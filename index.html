<script>
// --- keep any helper/game functions you already have above this block ---
// Make sure you only include this once (replace your previous chat code)

const WORKER_URL = "https://aiworker.thefoxsss6969.workers.dev";

/* add image upload UI into chat container */
(function addImageUploadUI(){
  const chatContainer = document.querySelector('.chat-container');
  if(!chatContainer) return;
  // create row with file input and label button
  const row = document.createElement('div');
  row.style.display = 'flex';
  row.style.gap = '8px';
  row.style.marginBottom = '8px';
  row.style.justifyContent = 'center';
  row.style.alignItems = 'center';

  const fileInput = document.createElement('input');
  fileInput.type = 'file';
  fileInput.accept = 'image/*';
  fileInput.style.display = 'none';
  fileInput.id = 'chatImageInput';

  const btn = document.createElement('button');
  btn.className = 'chat-send-btn';
  btn.type = 'button';
  btn.textContent = '📷 Upload';
  btn.title = 'Upload an image for the AI to analyze';
  btn.style.padding = '8px 12px';
  btn.style.fontSize = '10px';

  btn.addEventListener('click', ()=> fileInput.click());
  fileInput.addEventListener('change', async (e)=>{
    const file = e.target.files && e.target.files[0];
    if(!file) return;
    // read as data URL
    const reader = new FileReader();
    reader.onload = async () => {
      const dataUrl = reader.result; // data:image/png;base64,....
      // add user image bubble
      addMessage('user', '[image uploaded]', false);
      // send image to worker using streaming so the reply shows progressively
      await sendToWorkerStream({ image: { dataUrl, name: file.name } });
    };
    reader.readAsDataURL(file);
    // clear selection so same file can be uploaded again
    fileInput.value = '';
  });

  // insert row at top of chat input container
  const chatInputContainer = document.querySelector('.chat-input-container');
  if(chatInputContainer){
    chatInputContainer.parentNode.insertBefore(row, chatInputContainer);
    row.appendChild(fileInput);
    row.appendChild(btn);
  }
})();

/* DOM references (assumes same IDs as before) */
const chatMessages = document.getElementById('chatMessages');
const chatInput = document.getElementById('chatInput');
const chatSendBtn = document.getElementById('chatSendBtn');

/* message helpers */
function addMessage(who, text, isHTML=false){
  const div = document.createElement('div');
  div.className = 'chat-message ' + (who === 'user' ? 'user' : 'ai');
  if(isHTML) div.innerHTML = text;
  else div.textContent = text;
  chatMessages.appendChild(div);
  chatMessages.scrollTop = chatMessages.scrollHeight;
  return div;
}

/* typing placeholder bubble for streaming */
function createAIStreamBubble(){
  const div = document.createElement('div');
  div.className = 'chat-message ai';
  const pre = document.createElement('div');
  pre.style.whiteSpace = 'pre-wrap';
  pre.style.wordBreak = 'break-word';
  div.appendChild(pre);
  chatMessages.appendChild(div);
  chatMessages.scrollTop = chatMessages.scrollHeight;
  return { container: div, pre };
}

/* Build messages for worker:
   - If we have an image, include a user message that contains the data URL.
   - Otherwise include system + user message as before.
*/
function buildMessagesForPayload(opts){
  // opts: { text?: string, image?: { dataUrl, name } }
  const system = { role: "system", content: "You are a helpful assistant that can analyze images and answer questions about them." };
  const msgs = [ system ];

  if(opts?.image){
    // Put image data URL in the user content. This is accepted by vision-capable models.
    msgs.push({ role: "user", content: `Image: ${opts.image.name}\n${opts.image.dataUrl}` });
    if(opts?.text) msgs.push({ role: "user", content: opts.text });
  } else if (opts?.text) {
    msgs.push({ role: "user", content: opts.text });
  }
  return msgs;
}

/* ---------------- Streaming flow ----------------
 We request streaming from the worker by setting stream:true in body.
 The Worker proxies OpenAI's SSE/text stream; here we read the response body
 and append chunks to the AI bubble progressively.
*/
async function sendToWorkerStream(opts){
  // opts = { text?, image? }
  const payload = {
    messages: buildMessagesForPayload(opts),
    stream: true,
    temperature: 0.7,
    max_tokens: 1000
  };

  // create bubble and writer
  const { container, pre } = createAIStreamBubble();

  try {
    const resp = await fetch(WORKER_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
    });

    if(!resp.ok){
      const txt = await resp.text().catch(()=>`HTTP ${resp.status}`);
      container.remove();
      addMessage('ai', `⚠️ Worker error: ${txt}`);
      return;
    }

    // Read stream
    const reader = resp.body.getReader();
    const decoder = new TextDecoder();
    let done = false;
    let accumulated = '';

    while(!done){
      const { value, done: d } = await reader.read();
      done = d;
      if(value){
        const chunk = decoder.decode(value, { stream: true });
        // OpenAI SSE sometimes sends "data: [JSON]\n\n" parts; remove "data: " prefixes
        // and handle possible [DONE]
        const normalized = chunk.replace(/\r/g,'');
        // parse SSE-like chunks
        // naive approach: strip "data: " and append remaining text; if it's JSON, extract content
        const parts = normalized.split(/\n\n/);
        for(const part of parts){
          if(!part) continue;
          const lines = part.split('\n');
          for(const line of lines){
            const trimmed = line.trim();
            if(!trimmed) continue;
            if(trimmed === 'data: [DONE]' || trimmed === '[DONE]') {
              // stream finished
              done = true;
              break;
            }
            const maybe = trimmed.replace(/^data:\s*/, '');
            // try parse JSON
            try {
              const obj = JSON.parse(maybe);
              // OpenAI chunk may contain delta with content
              if(obj?.choices?.length){
                const ch = obj.choices[0];
                const token = ch.delta?.content ?? ch?.message?.content ?? '';
                if(token) {
                  accumulated += token;
                  pre.textContent = accumulated;
                  chatMessages.scrollTop = chatMessages.scrollHeight;
                }
              } else {
                // fallback, append text
                accumulated += maybe;
                pre.textContent = accumulated;
                chatMessages.scrollTop = chatMessages.scrollHeight;
              }
            } catch(e){
              // not JSON — append raw
              accumulated += maybe;
              pre.textContent = accumulated;
              chatMessages.scrollTop = chatMessages.scrollHeight;
            }
          }
        }
      }
    }

    // final done: ensure any remaining content is shown
    if(accumulated && pre.textContent !== accumulated) pre.textContent = accumulated;
    chatMessages.scrollTop = chatMessages.scrollHeight;
  } catch (err) {
    container.remove();
    console.error(err);
    addMessage('ai', '⚠️ Network error or worker stream failed.');
  }
}

/* Non-stream fallback: simple request/response (keeps old behaviour) */
async function sendToWorkerOnce(text){
  try{
    const payload = { messages: buildMessagesForPayload({ text }), stream: false, temperature: 0.7 };
    const resp = await fetch(WORKER_URL, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload)
    });
    const data = await resp.json().catch(()=>null);
    if(!data){
      addMessage('ai','⚠️ Invalid response from worker.');
      return;
    }
    if(Array.isArray(data.choices) && data.choices.length){
      const reply = data.choices[0].message?.content ?? data.choices[0].text ?? JSON.stringify(data.choices[0]);
      addMessage('ai', reply);
    } else if(data.error){
      addMessage('ai', `OpenAI error: ${data.error.message||JSON.stringify(data.error)}`);
    } else {
      addMessage('ai', JSON.stringify(data));
    }
  }catch(err){
    console.error(err);
    addMessage('ai','⚠️ Error contacting worker.');
  }
}

/* Hook up chat send button and Enter key.
   We'll use streaming by default for quicker UX.
*/
chatSendBtn.addEventListener('click', async ()=>{
  const text = chatInput.value.trim();
  if(!text) return;
  addMessage('user', text);
  chatInput.value = '';
  // stream the reply
  await sendToWorkerStream({ text });
});

chatInput.addEventListener('keydown', (e)=>{
  if(e.key === 'Enter'){ e.preventDefault(); chatSendBtn.click(); }
});
</script>
